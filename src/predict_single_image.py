import os
import random
from PIL import Image
import torch
from torchvision import transforms
from model import get_model
from config import IMG_SIZE, CLASSES, DEVICE  # MODEL_PATH kaldÄ±rÄ±ldÄ±!

def predict_single_image():
    print("Script baÅŸladÄ±")

    # MODEL SEÃ‡Ä°MÄ°
    model_dir = "saved_model"
    model_files = [f for f in os.listdir(model_dir) if f.endswith(".pth")]

    print("\n Mevcut modeller:")
    for i, model_name in enumerate(model_files):
        print(f"{i}: {model_name}")

    choice = int(input("\n Kullanmak istediÄŸiniz modeli seÃ§in (index girin): "))
    MODEL_PATH = os.path.join(model_dir, model_files[choice])
    print(f" SeÃ§ilen model: {MODEL_PATH}")

    # Dataset test dizini
    dataset_root = os.path.join("data", "breast_cancer_dataset_split", "test")

    selected_class = random.choice(CLASSES)
    class_path = os.path.join(dataset_root, selected_class)

    image_files = [
        f for f in os.listdir(class_path)
        if f.lower().endswith(".png") and "_mask" not in f
    ]

    if not image_files:
        print("Uygun gÃ¶rÃ¼ntÃ¼ bulunamadÄ±.")
        return

    image_file = random.choice(image_files)
    image_path = os.path.join(class_path, image_file)

    print(f"SeÃ§ilen sÄ±nÄ±f: {selected_class}")
    print(f"GÃ¶rsel adÄ±: {image_file}")
    print(f"Dosya mevcut mu? {os.path.exists(image_path)}")

    import matplotlib.pyplot as plt


    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Lambda(lambda img: img.convert("RGB")),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5],
                             [0.5, 0.5, 0.5])
    ])

    image = Image.open(image_path)
    image = transform(image).unsqueeze(0).to(DEVICE)

    model = get_model().to(DEVICE)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.eval()


    with torch.no_grad():
        outputs = model(image)
        if outputs is None:
            print("âŒ Model Ã§Ä±ktÄ± Ã¼retmedi.")
            return

        _, pred = torch.max(outputs, 1)

        try:
            predicted_class = CLASSES[pred.item()]
        except Exception as e:
            print(f"âŒ CLASSES hatasÄ±: {e}")
            return

        probs = torch.nn.functional.softmax(outputs, dim=1)

    print(" SÄ±nÄ±f olasÄ±lÄ±klarÄ±:", probs.cpu().numpy())
    print(f"\n Tahmin edilen sÄ±nÄ±f: {predicted_class}")
    print(f" GerÃ§ek sÄ±nÄ±f       : {selected_class}")

    from llm_inference import get_llm_response  
    llm_output = get_llm_response(predicted_class)
    print("\nğŸ“˜ LLM'den aÃ§Ä±klama:")
    print(llm_output)


    img = Image.open(image_path)
    plt.imshow(img)
    plt.title(f"Tahmin: {predicted_class}")
    plt.axis('off')
    plt.show()


if __name__ == "__main__":
    predict_single_image()
